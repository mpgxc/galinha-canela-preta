{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1d0f1a-6b99-4d3a-8c81-e4031c1186f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 02:45:19.561361: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-11 02:45:19.754871: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-11 02:45:19.754885: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-11 02:45:20.342832: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-11 02:45:20.342889: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-11 02:45:20.342893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "\n",
    "from tqdm import tqdm \n",
    "from glob import glob\n",
    "from skimage.io import imread\n",
    "from skimage.measure import label, regionprops_table\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy import stats\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from skimage import io\n",
    "from keras import backend as K\n",
    "from tensorflow_addons.metrics import RSquare\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from skimage import data, color\n",
    "from skimage.transform import resize\n",
    "from commons import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be99c861-a9b5-4b1c-a2fc-a298528dd065",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fd4175-4f6b-47e3-9f53-c9bb6e473f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluate(true, predicted):\n",
    "    \n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    \n",
    "    print('MAE:', mae)\n",
    "    print('MSE:', mse)\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2 Square', r2_square)\n",
    "    \n",
    "def run_all_regressions(X_train, X_test, Y_train, Y_test, regs):\n",
    "\n",
    "    for name, model in regs.items():\n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        print(f'\\n-----{name}------')\n",
    "        print('[Train] -------------')\n",
    "        print_evaluate(Y_train, model.predict(X_train))\n",
    "\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        print('[Test] --------------')\n",
    "        print_evaluate(Y_test, model.predict(X_test))\n",
    "\n",
    "def create_dataset(path_images):\n",
    "    anilhas = []\n",
    "    paths = []\n",
    "    anilhas_merged = []\n",
    "    paths_merged = []\n",
    "\n",
    "    for index in glob(f\"{path_images}/*\"):\n",
    "        anilha, *_ = re.findall(r'\\d+', index)\n",
    "        all_broilers = glob(index + \"/**\")\n",
    "\n",
    "        anilhas.append([anilha] * len(all_broilers))\n",
    "        paths.append(all_broilers)\n",
    "\n",
    "    for anilha, path in zip(anilhas, paths):\n",
    "        anilhas_merged = np.concatenate([anilhas_merged, anilha])\n",
    "        paths_merged = np.concatenate([paths_merged, path])\n",
    "        \n",
    "    return anilhas_merged.astype(int), paths_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b07e52b-eab2-4ad6-b157-b3f0cdd4ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling_datatset(anilhas, paths):\n",
    "    \n",
    "    df_weights = pd.read_csv(\"annotations.csv\")\n",
    "\n",
    "    df_out = pd.DataFrame({\n",
    "        \"label\": anilhas,\n",
    "        \"path\": paths,\n",
    "        \"weight\": -1\n",
    "    }) \n",
    "\n",
    "    for (index, weight) in zip(df_weights.id,  df_weights.weight):\n",
    "        df_out.weight.iloc[df_out[df_out.label == index].index] = weight\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "def loading_dataset_images(df, x_size=120, y_size=120):\n",
    "    return np.array([resize(imread(path), (x_size, y_size), anti_aliasing=True) \n",
    "                     for path in df.path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08cccb5d-bb4d-4d23-9b1c-178b0dea9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size, y_size = 512 // 2, 424 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08058b2c-e24e-4766-92cc-0a4d7703b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importe imagens de treino\n",
    "anilhas_train, paths_train = create_dataset(\"outputs/broilers_with_neck\")\n",
    "df_train = labeling_datatset(anilhas_train, paths_train)\n",
    "\n",
    "images_train =  loading_dataset_images(df_train, x_size, y_size)\n",
    "\n",
    "#Importe imagens de teste\n",
    "paths_test = glob(\"selecionadas/*\")\n",
    "anilhas_test = list(map(lambda i: int(re.findall(r'\\d+', i)[0]), paths_test))\n",
    "\n",
    "df_test = labeling_datatset(anilhas_test, paths_test)\n",
    "images_test =  loading_dataset_images(df_test, x_size, y_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46788f2f-5fb9-42c0-9006-18c20941ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images_train, \n",
    "                                                    anilhas_train, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = images_train, images_test, anilhas_train, anilhas_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fac6185-fd3c-48a9-8946-372d0fe551f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = len(images_train)\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS=30\n",
    "STEPS_PER_EPOCH = N_TRAIN // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a57711-f9a0-44ad-a85e-56dfc0376f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 02:45:26.116378: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-11 02:45:26.116397: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-11 02:45:26.116411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mpgxc): /proc/driver/nvidia/version does not exist\n",
      "2023-02-11 02:45:26.116781: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(6,\n",
    "                        (5, 5),\n",
    "                        activation='relu',\n",
    "                        padding=\"same\",\n",
    "                        kernel_regularizer=l2(0.01), \n",
    "                        bias_regularizer=l2(0.01), \n",
    "                        input_shape=(x_size, y_size, 1)),\n",
    "    \n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(16,\n",
    "                        (5, 5),\n",
    "                        activation='relu', \n",
    "                        padding=\"same\",\n",
    "                        kernel_regularizer=l2(0.01),\n",
    "                        bias_regularizer=l2(0.01)),\n",
    "    \n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    #FC\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(120, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Dense(84, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(units=1, activation=\"linear\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c0b928a-b401-4522-8406-cf6d95bbace5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 106, 6)       156       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 53, 6)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64, 53, 6)        24        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 53, 16)        2416      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 26, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 26, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 26, 16)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 13312)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               1597560   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 120)              480       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 84)               336       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,611,285\n",
      "Trainable params: 1,610,833\n",
      "Non-trainable params: 452\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8007c40a-cc6e-4c78-a99f-7162bb767b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.InverseTimeDecay(\n",
    "    0.001,\n",
    "    decay_steps=STEPS_PER_EPOCH * 1000,\n",
    "    decay_rate=1,\n",
    "    staircase=False)\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "              metrics=[RSquare()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f7be50a-1605-4e64-97b6-bc2cff57f21d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "71/71 [==============================] - 4s 46ms/step - loss: 8551.3896 - r_square: -2.3259 - val_loss: 9424.2949 - val_r_square: -3.4147\n",
      "Epoch 2/30\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 8112.4883 - r_square: -2.1552 - val_loss: 9436.7266 - val_r_square: -3.4205\n",
      "Epoch 3/30\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 7495.5610 - r_square: -1.9152 - val_loss: 9361.0439 - val_r_square: -3.3851\n",
      "Epoch 4/30\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 6557.6816 - r_square: -1.5505 - val_loss: 11322.2041 - val_r_square: -4.3038\n",
      "Epoch 5/30\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 5394.4634 - r_square: -1.0980 - val_loss: 10391.9922 - val_r_square: -3.8680\n",
      "Epoch 6/30\n",
      "71/71 [==============================] - 3s 40ms/step - loss: 4428.7856 - r_square: -0.7225 - val_loss: 7991.4790 - val_r_square: -2.7435\n",
      "Epoch 7/30\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 3571.9417 - r_square: -0.3892 - val_loss: 6013.9116 - val_r_square: -1.8171\n",
      "Epoch 8/30\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 2731.6011 - r_square: -0.0624 - val_loss: 3813.9146 - val_r_square: -0.7865\n",
      "Epoch 9/30\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 2071.3821 - r_square: 0.1944 - val_loss: 3960.6230 - val_r_square: -0.8553\n",
      "Epoch 10/30\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1512.6191 - r_square: 0.4117 - val_loss: 2218.1221 - val_r_square: -0.0390\n",
      "Epoch 11/30\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 1082.5605 - r_square: 0.5790 - val_loss: 2477.4893 - val_r_square: -0.1605\n",
      "Epoch 12/30\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 914.5539 - r_square: 0.6444 - val_loss: 1814.0416 - val_r_square: 0.1503\n",
      "Epoch 13/30\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 795.7590 - r_square: 0.6906 - val_loss: 1470.5571 - val_r_square: 0.3112\n",
      "Epoch 14/30\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 656.8833 - r_square: 0.7446 - val_loss: 1892.5565 - val_r_square: 0.1135\n",
      "Epoch 15/30\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 590.8967 - r_square: 0.7702 - val_loss: 1703.0653 - val_r_square: 0.2023\n",
      "Epoch 16/30\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 497.3147 - r_square: 0.8066 - val_loss: 1448.5259 - val_r_square: 0.3215\n",
      "Epoch 17/30\n",
      "71/71 [==============================] - 4s 51ms/step - loss: 437.1420 - r_square: 0.8300 - val_loss: 1336.7593 - val_r_square: 0.3739\n",
      "Epoch 18/30\n",
      "71/71 [==============================] - 3s 48ms/step - loss: 508.3894 - r_square: 0.8023 - val_loss: 1417.0067 - val_r_square: 0.3363\n",
      "Epoch 19/30\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 517.7816 - r_square: 0.7987 - val_loss: 1445.7428 - val_r_square: 0.3228\n",
      "Epoch 20/30\n",
      "71/71 [==============================] - 3s 45ms/step - loss: 569.3331 - r_square: 0.7786 - val_loss: 1412.2332 - val_r_square: 0.3385\n",
      "Epoch 21/30\n",
      "71/71 [==============================] - 3s 44ms/step - loss: 601.9692 - r_square: 0.7659 - val_loss: 1613.3568 - val_r_square: 0.2443\n",
      "Epoch 22/30\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 449.9465 - r_square: 0.8251 - val_loss: 1512.8625 - val_r_square: 0.2914\n",
      "Epoch 23/30\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 467.6434 - r_square: 0.8182 - val_loss: 1389.7161 - val_r_square: 0.3491\n",
      "Epoch 24/30\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 590.4398 - r_square: 0.7704 - val_loss: 1553.4763 - val_r_square: 0.2724\n",
      "Epoch 25/30\n",
      "71/71 [==============================] - 3s 42ms/step - loss: 542.4279 - r_square: 0.7891 - val_loss: 1538.9905 - val_r_square: 0.2791\n",
      "Epoch 26/30\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 499.7907 - r_square: 0.8057 - val_loss: 1680.4686 - val_r_square: 0.2129\n",
      "Epoch 27/30\n",
      "71/71 [==============================] - 3s 41ms/step - loss: 479.5095 - r_square: 0.8136 - val_loss: 1520.1226 - val_r_square: 0.2880\n"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_split=0.1,\n",
    "                    shuffle=True,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "109fef63-9294-4400-b993-1f2bcc70a522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 12ms/step\n",
      "MAE: 9.859236488327051\n",
      "MSE: 244.5280890523883\n",
      "RMSE: 15.637393934169092\n",
      "R2 Square 0.9033833856350846\n"
     ]
    }
   ],
   "source": [
    "y_train_preds = model.predict(np.asarray(X_train)).reshape(-1)\n",
    "print_evaluate(y_train, y_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bb14ec0-de03-464a-8982-94e7751730a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 12ms/step\n",
      "MAE: 36.0234725736774\n",
      "MSE: 2186.2943706345213\n",
      "RMSE: 46.757826838236625\n",
      "R2 Square 0.15213092863152344\n"
     ]
    }
   ],
   "source": [
    "y_test_preds = model.predict(np.asarray(X_test)).reshape(-1)\n",
    "print_evaluate(y_test, y_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408df1f8-3c66-422a-bcbd-8f8cddb5479f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
